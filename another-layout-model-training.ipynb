{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Layout Parser Model Training**","metadata":{}},{"cell_type":"markdown","source":"https://github.com/Layout-Parser/layout-model-training/blob/master/tools/train_net.py\n\nhttps://towardsdatascience.com/auto-parse-and-understand-any-document-5d72e81b0be9\n\nhttps://layout-parser.readthedocs.io/en/latest/api_doc/models.html","metadata":{}},{"cell_type":"markdown","source":"# Detectron2\n\nDetectron2 is Facebook AI Research's next generation software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, Detectron, and it originates from maskrcnn-benchmark","metadata":{}},{"cell_type":"markdown","source":"### Installation\n* detectron2 is not pre-installed in this kaggle docker, so let's install it.\n* we need to know CUDA and pytorch version to install correct detectron2.","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:18:48.452183Z","iopub.execute_input":"2021-10-09T04:18:48.452493Z","iopub.status.idle":"2021-10-09T04:18:49.259178Z","shell.execute_reply.started":"2021-10-09T04:18:48.452409Z","shell.execute_reply":"2021-10-09T04:18:49.258389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:18:49.26113Z","iopub.execute_input":"2021-10-09T04:18:49.261573Z","iopub.status.idle":"2021-10-09T04:18:49.92711Z","shell.execute_reply.started":"2021-10-09T04:18:49.261531Z","shell.execute_reply":"2021-10-09T04:18:49.926314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:18:49.928749Z","iopub.execute_input":"2021-10-09T04:18:49.929047Z","iopub.status.idle":"2021-10-09T04:18:54.351091Z","shell.execute_reply.started":"2021-10-09T04:18:49.929007Z","shell.execute_reply":"2021-10-09T04:18:54.35031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* It seems CUDA=11.0 and torch==1.7.0 is used in this kaggle docker image.\n* See installation for details. https://detectron2.readthedocs.io/en/latest/tutorials/install.html","metadata":{}},{"cell_type":"markdown","source":"### Install Pre-Built Detectron2","metadata":{}},{"cell_type":"code","source":"!pip install detectron2 -f \\\n  https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-09T04:18:54.353183Z","iopub.execute_input":"2021-10-09T04:18:54.353613Z","iopub.status.idle":"2021-10-09T04:19:23.72403Z","shell.execute_reply.started":"2021-10-09T04:18:54.353575Z","shell.execute_reply":"2021-10-09T04:19:23.723213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# importing libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pandas as pd \nfrom tqdm import tqdm\nfrom tqdm import tqdm_notebook as tqdm # progress bar\nfrom datetime import datetime\nimport time\nimport matplotlib.pyplot as plt\n#from pycocotools.coco import COCO\nimport os, json, cv2, random\nimport skimage.io as io\nimport copy\nfrom pathlib import Path\nfrom typing import Optional\n\n\n# torch\nimport torch\n\n# Albumenatations\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n#from pycocotools.coco import COCO\nfrom sklearn.model_selection import StratifiedKFold\n\n# glob\nfrom glob import glob\n\n# numba\nimport numba\nfrom numba import jit\n\nimport warnings\nwarnings.filterwarnings('ignore') #Ignore \"future\" warnings and Data-Frame-Slicing warnings.\n\n\n# detectron2\nfrom detectron2.structures import BoxMode\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer, launch\nfrom detectron2.evaluation import COCOEvaluator\nfrom detectron2.structures import BoxMode\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.utils.visualizer import Visualizer\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\n\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\nimport detectron2.data.transforms as T\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n\nsetup_logger()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:23.727411Z","iopub.execute_input":"2021-10-09T04:19:23.727641Z","iopub.status.idle":"2021-10-09T04:19:26.281217Z","shell.execute_reply.started":"2021-10-09T04:19:23.727613Z","shell.execute_reply":"2021-10-09T04:19:26.280458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open('/kaggle/input/papers-images/train/train/samples.json',)\nthing_classes  = []\nthing_classes_id = {}\ndata_annotations=[]\ndata = json.load(f)\n#----Images----\ndata_images=data['images']\n#---annotations-\nfor i in data['annotations']:\n    annot_obj ={\"id\": i['id'],\"image_id\": i['image_id'],\"category_id\":i['category_id'],\n          \"x_min\":i['bbox'][0], #left\n          \"y_min\":i['bbox'][1], #top\n          \"x_max\":i['bbox'][0]+i['bbox'][2], #left+width\n          \"y_max\":i['bbox'][1]+i['bbox'][3] #top+hieght\n         }\n    data_annotations.append(annot_obj) \n#---categories-\nfor i in data['categories']:\n    thing_classes.append(i['name'])\n    thing_classes_id[i['name']]=i['id']\nf.close()\nprint(\"thing_classes=\",thing_classes)\nprint(\"thing_classes_id=\",thing_classes_id)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.282595Z","iopub.execute_input":"2021-10-09T04:19:26.282879Z","iopub.status.idle":"2021-10-09T04:19:26.308112Z","shell.execute_reply.started":"2021-10-09T04:19:26.282845Z","shell.execute_reply":"2021-10-09T04:19:26.307364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thing_classes= ['None','text', 'title', 'list', 'table', 'figure']","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.309409Z","iopub.execute_input":"2021-10-09T04:19:26.309706Z","iopub.status.idle":"2021-10-09T04:19:26.314229Z","shell.execute_reply.started":"2021-10-09T04:19:26.309653Z","shell.execute_reply":"2021-10-09T04:19:26.313369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta = pd.DataFrame(data_images)\ntrain_meta = train_meta[['id', 'file_name', 'width', 'height']]\ntrain_meta = train_meta.rename(columns={\"id\":\"image_id\"})\nprint(\"train_meta size=\",len(train_meta))\ntrain_meta.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.315783Z","iopub.execute_input":"2021-10-09T04:19:26.316749Z","iopub.status.idle":"2021-10-09T04:19:26.343009Z","shell.execute_reply.started":"2021-10-09T04:19:26.316712Z","shell.execute_reply":"2021-10-09T04:19:26.342221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame(data_annotations)\nprint(\"train_df size=\",len(train_df))\ntrain_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.344345Z","iopub.execute_input":"2021-10-09T04:19:26.344597Z","iopub.status.idle":"2021-10-09T04:19:26.359246Z","shell.execute_reply.started":"2021-10-09T04:19:26.344565Z","shell.execute_reply":"2021-10-09T04:19:26.358282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# configs","metadata":{}},{"cell_type":"code","source":"imgdir=\"/kaggle/input/papers-images/train/train\"\n\ndebug=False\nsplit_mode=\"valid20\" # all_train Or  valid20 \nimage_Width=601\nimage_Height=792\n\nnum_folds=5\nSelected_fold=1 #1,2,3,4,5 ","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.363233Z","iopub.execute_input":"2021-10-09T04:19:26.363708Z","iopub.status.idle":"2021-10-09T04:19:26.368551Z","shell.execute_reply.started":"2021-10-09T04:19:26.363674Z","shell.execute_reply":"2021-10-09T04:19:26.367802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_PL_data_dicts(\n    imgdir: Path,\n    _train_df: pd.DataFrame,\n    _train_meta: pd.DataFrame,\n    use_cache: bool = True,\n    target_indices: Optional[np.ndarray] = None,\n    debug: bool = False,\n    data_type:str=\"train\"\n   \n):\n    if debug:\n            train_meta = train_meta.iloc[:100]  # For debug...\n    dataset_dicts = []\n    for index, train_meta_row in tqdm(_train_meta.iterrows(), total=len(_train_meta)):\n                    record = {}\n                    image_id,file_name, width,height = train_meta_row.values\n                    filename = str(f'{imgdir}/{file_name}')\n                    record[\"file_name\"] = filename\n                    record[\"image_id\"] = image_id\n                    record[\"width\"] = width\n                    record[\"height\"] = height\n                    objs = []\n                    for index2, row in _train_df.query(\"image_id == @image_id\").iterrows():\n                        class_id = row[\"category_id\"]\n                        bbox_resized = [\n                            float(row[\"x_min\"]),\n                            float(row[\"y_min\"]),\n                            float(row[\"x_max\"]),\n                            float(row[\"y_max\"]),\n                        ]\n                        obj = {\n                            \"bbox\": bbox_resized,\n                            \"bbox_mode\": BoxMode.XYXY_ABS,\n                            \"category_id\": class_id,\n                        }\n                        objs.append(obj)\n                    record[\"annotations\"] = objs\n                    dataset_dicts.append(record)\n                    \n    if target_indices is not None:\n        dataset_dicts = [dataset_dicts[i] for i in target_indices]\n\n    return dataset_dicts\n\n                                  ","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.370038Z","iopub.execute_input":"2021-10-09T04:19:26.370467Z","iopub.status.idle":"2021-10-09T04:19:26.3831Z","shell.execute_reply.started":"2021-10-09T04:19:26.370432Z","shell.execute_reply":"2021-10-09T04:19:26.382408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data_Resister_training=\"PL_data_train\";\nData_Resister_valid=\"PL_data_valid\";\n\nif split_mode == \"all_train\":\n    DatasetCatalog.register(\n        Data_Resister_training,\n        lambda: get_PL_data_dicts(\n            imgdir,\n            train_df,\n            train_meta,\n            debug=debug,\n            data_type=\"train\"\n        ),\n    )\n    MetadataCatalog.get(Data_Resister_training).set(thing_classes=thing_classes)\n    \n    \n    dataset_dicts_train = DatasetCatalog.get(Data_Resister_training)\n    metadata_dicts_train = MetadataCatalog.get(Data_Resister_training)\n    \n    \nelif split_mode == \"valid20\":\n\n    n_dataset = len(train_meta)\n    n_train = int(n_dataset * 0.95)\n    print(\"n_dataset\", n_dataset, \"n_train\", n_train)\n    rs = np.random.RandomState(12)\n    inds = rs.permutation(n_dataset)\n    train_inds, valid_inds = inds[:n_train], inds[n_train:]\n    DatasetCatalog.register(\n        Data_Resister_training,\n        lambda: get_PL_data_dicts(\n            imgdir,\n            train_df,\n            train_meta,\n            target_indices=train_inds,\n            debug=debug,\n            data_type=\"train\"\n        ),\n    )\n    MetadataCatalog.get(Data_Resister_training).set(thing_classes=thing_classes)\n    \n\n    DatasetCatalog.register(\n        Data_Resister_valid,\n        lambda: get_PL_data_dicts(\n            imgdir,\n            train_df,\n            train_meta,\n            target_indices=valid_inds,\n            debug=debug,\n            data_type=\"val\"\n            ),\n        )\n    MetadataCatalog.get(Data_Resister_valid).set(thing_classes=thing_classes)\n    \n    dataset_dicts_train = DatasetCatalog.get(Data_Resister_training)\n    metadata_dicts_train = MetadataCatalog.get(Data_Resister_training)\n\n    dataset_dicts_valid = DatasetCatalog.get(Data_Resister_valid)\n    metadata_dicts_valid = MetadataCatalog.get(Data_Resister_valid)\n    \nelse:\n    raise ValueError(f\"[ERROR] Unexpected value split_mode={split_mode}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.385534Z","iopub.execute_input":"2021-10-09T04:19:26.386104Z","iopub.status.idle":"2021-10-09T04:19:26.614984Z","shell.execute_reply.started":"2021-10-09T04:19:26.386069Z","shell.execute_reply":"2021-10-09T04:19:26.612519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"dicts training size=\",len(dataset_dicts_train),\"################  dicts valid size=\",len(dataset_dicts_valid))","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.617058Z","iopub.execute_input":"2021-10-09T04:19:26.617431Z","iopub.status.idle":"2021-10-09T04:19:26.623674Z","shell.execute_reply.started":"2021-10-09T04:19:26.617369Z","shell.execute_reply":"2021-10-09T04:19:26.622849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_dicts_train[11]","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.625329Z","iopub.execute_input":"2021-10-09T04:19:26.625705Z","iopub.status.idle":"2021-10-09T04:19:26.637123Z","shell.execute_reply.started":"2021-10-09T04:19:26.625637Z","shell.execute_reply":"2021-10-09T04:19:26.636223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_dicts_valid[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.638553Z","iopub.execute_input":"2021-10-09T04:19:26.638813Z","iopub.status.idle":"2021-10-09T04:19:26.648538Z","shell.execute_reply.started":"2021-10-09T04:19:26.638783Z","shell.execute_reply":"2021-10-09T04:19:26.647744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"markdown","source":"fig = plt.figure(figsize =(40,40))\nax = fig.add_subplot(1,1,1)\n\nd=dataset_dicts_valid[1]   \nimg = cv2.imread(d[\"file_name\"])\nv = Visualizer(img[:, :, ::-1],\n                metadata=metadata_dicts_valid, \n                scale=1.5, \n                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n)\nout = v.draw_dataset_dict(d)\nax.grid(False)\nax.axis('off')\nax.imshow(out.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:24:24.898373Z","iopub.status.idle":"2021-10-08T06:24:24.898792Z","shell.execute_reply.started":"2021-10-08T06:24:24.898569Z","shell.execute_reply":"2021-10-08T06:24:24.898591Z"}}},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"def custom_mapper(dataset_dict):\n    \n    dataset_dict = copy.deepcopy(dataset_dict)\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n    transform_list = [T.RandomBrightness(0.8, 1.2),\n                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False)\n                      ]\n    image, transforms = T.apply_transform_gens(transform_list, image)\n    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n\n    annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n        if obj.get(\"iscrowd\", 0) == 0\n    ]\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n    return dataset_dict\nclass AugTrainer(DefaultTrainer):\n    @classmethod\n    def build_train_loader(cls, cfg):\n        return build_detection_train_loader(cfg, mapper=custom_mapper)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:19:26.649981Z","iopub.execute_input":"2021-10-09T04:19:26.650283Z","iopub.status.idle":"2021-10-09T04:19:26.659639Z","shell.execute_reply.started":"2021-10-09T04:19:26.650245Z","shell.execute_reply":"2021-10-09T04:19:26.658805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = get_cfg()\nconfig_name = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\" \n\ncfg.merge_from_file(model_zoo.get_config_file(config_name))\n\ncfg.DATASETS.TRAIN = (Data_Resister_training,)\n\nif split_mode == \"all_train\":\n    cfg.DATASETS.TEST = ()\nelse:\n    cfg.DATASETS.TEST = (Data_Resister_valid,)\n    cfg.TEST.EVAL_PERIOD = 1000\n\ncfg.DATALOADER.NUM_WORKERS = 0\n#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\ncfg.MODEL.WEIGHTS=\"/kaggle/input/layout-parser-weights/Weights/faster_rcnn_R_50_FPN_3x/model_final.pth\"\n\n\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR = 0.02\n\ncfg.SOLVER.WARMUP_ITERS = 1000\ncfg.SOLVER.MAX_ITER = 20000 #adjust up if val mAP is still rising, adjust down if overfit\n#cfg.SOLVER.STEPS = (100, 500) # must be less than  MAX_ITER \n#cfg.SOLVER.GAMMA = 0.05\n\n\ncfg.SOLVER.CHECKPOINT_PERIOD = 100000  # Small value=Frequent save need a lot of storage.\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 4\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\n\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n\n\n#Training using custom trainer defined above\ntrainer = AugTrainer(cfg) \n#trainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:32.440548Z","iopub.execute_input":"2021-10-09T04:21:32.441385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluator = COCOEvaluator(Data_Resister_training, cfg, False, output_dir=\"./output/\")\n#cfg.MODEL.WEIGHTS=\"./output/model_final.pth\"\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set a custom testing threshold\nval_loader = build_detection_test_loader(cfg, Data_Resister_training)\ninference_on_dataset(trainer.model, val_loader, evaluator)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.834035Z","iopub.status.idle":"2021-10-09T04:21:30.834576Z","shell.execute_reply.started":"2021-10-09T04:21:30.834309Z","shell.execute_reply":"2021-10-09T04:21:30.834333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmetrics_df = pd.read_json(\"./output/metrics.json\", orient=\"records\", lines=True)\nmdf = metrics_df.sort_values(\"iteration\")\nmdf.head(10).T","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.836151Z","iopub.status.idle":"2021-10-09T04:21:30.836987Z","shell.execute_reply.started":"2021-10-09T04:21:30.836725Z","shell.execute_reply":"2021-10-09T04:21:30.836752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"total_loss\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\nif \"validation_loss\" in mdf.columns:\n    mdf2 = mdf[~mdf[\"validation_loss\"].isna()]\n    ax.plot(mdf2[\"iteration\"], mdf2[\"validation_loss\"], c=\"C1\", label=\"validation\")\n\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"Loss curve\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.838196Z","iopub.status.idle":"2021-10-09T04:21:30.838919Z","shell.execute_reply.started":"2021-10-09T04:21:30.838686Z","shell.execute_reply":"2021-10-09T04:21:30.838709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"fast_rcnn/cls_accuracy\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"fast_rcnn/cls_accuracy\"], c=\"C0\", label=\"train\")\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"Accuracy curve\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.840006Z","iopub.status.idle":"2021-10-09T04:21:30.840807Z","shell.execute_reply.started":"2021-10-09T04:21:30.840544Z","shell.execute_reply":"2021-10-09T04:21:30.840569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nmdf1 = mdf[~mdf[\"loss_box_reg\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"loss_box_reg\"], c=\"C0\", label=\"train\")\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"loss_box_reg\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.841974Z","iopub.status.idle":"2021-10-09T04:21:30.842517Z","shell.execute_reply.started":"2021-10-09T04:21:30.84227Z","shell.execute_reply":"2021-10-09T04:21:30.842293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U layoutparser ","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.843948Z","iopub.status.idle":"2021-10-09T04:21:30.844365Z","shell.execute_reply.started":"2021-10-09T04:21:30.844141Z","shell.execute_reply":"2021-10-09T04:21:30.844163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import layoutparser as lp","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.845646Z","iopub.status.idle":"2021-10-09T04:21:30.846204Z","shell.execute_reply.started":"2021-10-09T04:21:30.845953Z","shell.execute_reply":"2021-10-09T04:21:30.845977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lp.Detectron2LayoutModel('lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n                                 './output/model_final.pth',\n                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n                                 label_map={0: \"text\", 1: \"title\", 2: \"list\", 3:\"table\", 4:\"figure\"})\n#######################################################\nimage = cv2.imread('/kaggle/input/papers-images/train/train/PMC3576793_00004.jpg')\n#plt.imshow(image)\ncolor_map = {\n    'text':   'red',\n    'title':  'blue',\n    'list':   'green',\n    'table':  'yellow',\n    'figure': 'pink',\n}\n\nlayout_predicted = model.detect(image)\nlp.draw_box(image,\n              [b.set(id=f'{b.type}/{b.score:.2f}') for b in layout_predicted],\n              color_map=color_map,\n              show_element_id=True, id_font_size=10,\n              id_text_background_color='black',\n              id_text_color='white')","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.847701Z","iopub.status.idle":"2021-10-09T04:21:30.848124Z","shell.execute_reply.started":"2021-10-09T04:21:30.84789Z","shell.execute_reply":"2021-10-09T04:21:30.847912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n#cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.44   # set a custom testing threshold for this model\n#cfg.DATASETS.TEST = (\"Data_Resister_training\", )\npredictor = DefaultPredictor(cfg)\n\n###############################################################\n\nfig, ax = plt.subplots(2, 2, figsize =(20,20))\nindices=[ax[0][0],ax[1][0],ax[0][1],ax[1][1] ]\ni=-1\n# Show some qualitative results by predicting on test set images\nNUM_TEST_SAMPLES = 4\nsamples = random.sample(dataset_dicts_train, NUM_TEST_SAMPLES)\nfor i, sample in enumerate(samples):\n    img = cv2.imread(sample[\"file_name\"])\n    outputs = predictor(img)\n    visualizer = Visualizer(img, metadata=metadata_dicts_train,scale=0.5,)\n    visualizer = visualizer.draw_instance_predictions(\n        outputs[\"instances\"].to(\"cpu\"))\n    display_img = visualizer.get_image()[:, :, ::-1]\n    indices[i].grid(False)\n    indices[i].imshow(display_img)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:21:30.849506Z","iopub.status.idle":"2021-10-09T04:21:30.849934Z","shell.execute_reply.started":"2021-10-09T04:21:30.84971Z","shell.execute_reply":"2021-10-09T04:21:30.849732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### References\n* https://layout-parser.readthedocs.io/en/latest/notes/installation.html","metadata":{}}]}